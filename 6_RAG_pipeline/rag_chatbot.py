import os
import io
import time
import json
import boto3
import streamlit as st
from langchain_aws import ChatBedrock
import psycopg2
from dotenv import load_dotenv


load_dotenv()

st.set_page_config(
    page_title="ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“š",
    layout="wide"
)

@st.cache_resource
def init_bedrock():
    bedrock_client = boto3.client("bedrock-runtime", region_name="us-east-1")
    bedrock_embedding = boto3.client("bedrock-runtime", region_name="us-east-1")
    bedrock = ChatBedrock(
        client=bedrock_client,
        model_id="anthropic.claude-3-sonnet-20240229-v1:0",
        model_kwargs={"anthropic_version": "bedrock-2023-05-31"},
    )
    return bedrock, bedrock_embedding

@st.cache_resource
def init_s3():
    return boto3.client('s3', region_name="us-east-1")

def get_db_connection():
    conn = psycopg2.connect(
        host=os.getenv('DB_HOST'),
        database=os.getenv('DB_NAME'),
        user=os.getenv('DB_USER'),
        password=os.getenv('DB_PASSWORD')
    )
    conn.autocommit = True  
    return conn

def get_embedding(text, bedrock_embedding):
    response = bedrock_embedding.invoke_model(
        modelId='amazon.titan-embed-text-v1',
        contentType='application/json',
        accept='application/json',
        body=json.dumps({"inputText": text})
    )
    response_body = json.loads(response.get('body').read().decode())
    embedding = response_body['embedding']
    return embedding

def find_similar_chunks(query_embedding, k=3):
    """ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT content, metadata,
                   1 - (embedding <=> %s::vector) as similarity
            FROM documents
            ORDER BY embedding <=> %s::vector
            LIMIT %s;
        """, (query_embedding, query_embedding, k))
        
        results = cursor.fetchall()
        return [(row[0], row[1]) for row in results]
    finally:
        cursor.close()
        conn.close()

def check_documents_exist():
    """ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute("SELECT EXISTS(SELECT 1 FROM documents LIMIT 1)")
        return cursor.fetchone()[0]

if 'messages' not in st.session_state:
    st.session_state.messages = []

st.title("ğŸ” ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")
st.caption("RAG(Retrieval-Augmented Generation) ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰")

documents_exist = check_documents_exist()

with st.sidebar:
    
    with st.container():
        st.markdown("### ğŸ“‹ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. ì²˜ë¦¬ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        3. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ ë‹µë³€ì„ ë°›ìœ¼ì„¸ìš”
        """)
    
    st.markdown("---")
    
    # ë¬¸ì„œê°€ ì—†ì„ ë•Œë§Œ ì—…ë¡œë“œ UI í‘œì‹œ
    if not documents_exist:
        with st.container():
            st.markdown("### ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "PDF íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì„¸ìš”",
                type=['pdf'],
                help="PDF í˜•ì‹ë§Œ ê°€ëŠ¥"
            )
            
            if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", key="process_button", use_container_width=True):
                if uploaded_file:
                    try:
                        s3 = init_s3()
                        bucket_name = os.getenv('BUCKET_NAME')
                        file_name = uploaded_file.name
                        file_bytes = io.BytesIO(uploaded_file.getvalue())
                        
                        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            s3.upload_fileobj(
                                file_bytes,
                                bucket_name,
                                f"{file_name}",
                                ExtraArgs={'ContentType': 'application/pdf'}
                            )
                        
                        st.success("âœ… PDFê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤...30ì´ˆ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤."):
                            time.sleep(40)
                            
                        if check_documents_exist():
                            st.rerun()
                    except Exception as e:
                        st.error(f"âš ï¸ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                else:
                    st.warning("âš ï¸ PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        st.success("âœ… ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])


prompt = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...")
if prompt:
    if not documents_exist:  
        st.warning("âš ï¸ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        try:
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    bedrock, bedrock_embedding = init_bedrock()
                    
                    # 1. ì§ˆë¬¸ì˜ ì„ë² ë”© ìƒì„±
                    query_embedding = get_embedding(prompt, bedrock_embedding)
                    
                    # 2. ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
                    similar_chunks = find_similar_chunks(query_embedding)
                    
                    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                    context = "\n\n".join([chunk[0] for chunk in similar_chunks])
                    
                    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    prompt_with_context = f"""ë‹¤ìŒì€ í•™ì‚¬ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ê³¼ ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:
    
    ì§ˆë¬¸: {prompt}
    
    ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:
    {context}
    
    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. 
    ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì–¸ê¸‰í•˜ì§€ ë§ê³ , í™•ì‹¤í•œ ì •ë³´ë§Œ ë‹µë³€ì— í¬í•¨í•´ì£¼ì„¸ìš”."""
                    
                    # 5. ë‹µë³€ ìƒì„±
                    response = bedrock.invoke(prompt_with_context)
                    
                    st.write(response.content)
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": response.content
                    })
                    
                    # 6. ì°¸ê³ í•œ ë¬¸ì„œ í‘œì‹œ
                    with st.expander("ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ"):
                        for i, (content, metadata) in enumerate(similar_chunks, 1):
                            st.markdown(f"**ë¬¸ì„œ {i}:**")
                            st.write(content)
                            if metadata:
                                st.caption(f"ì¶œì²˜: {metadata.get('page', 'N/A')}í˜ì´ì§€")
                    
                    with st.expander("ğŸ“Š ìƒì„¸ ì •ë³´"):
                        st.json({
                            "ëª¨ë¸": response.additional_kwargs.get("model_id", "N/A"),
                            "í† í° ì‚¬ìš©ëŸ‰": response.additional_kwargs.get("usage", {}),
                            "ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜": len(similar_chunks)
                        })
        except Exception as e:
            st.error(f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")