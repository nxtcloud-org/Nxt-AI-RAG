import os
import io
import time
import json
import boto3
import psycopg2
import streamlit as st
from dotenv import load_dotenv
from langchain_aws import ChatBedrock, BedrockEmbeddings
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import HumanMessage

load_dotenv()

st.set_page_config(
    page_title="ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = InMemoryChatMessageHistory()  
if 'messages' not in st.session_state:
    st.session_state.messages = [] 
if 'show_upload' not in st.session_state:
    st.session_state.show_upload = True

def get_session_history(session_id):
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = InMemoryChatMessageHistory()
    return st.session_state.chat_history

@st.cache_resource
def init_bedrock():
    bedrock_client = boto3.client("bedrock-runtime", region_name="us-east-1")
    
    llm = ChatBedrock(
        client=bedrock_client,
        model_id="anthropic.claude-3-haiku-20240307-v1:0",
        model_kwargs={"anthropic_version": "bedrock-2023-05-31"},
    )
    
    conversation = RunnableWithMessageHistory(
        llm,
        get_session_history,
        max_history=3 
    ).with_config(configurable={"session_id": "default"})
    
    return conversation, bedrock_client

@st.cache_resource
def init_s3():
    return boto3.client('s3', region_name="us-east-1")

def get_db_connection():
    conn = psycopg2.connect(
        host=os.getenv('DB_HOST'),
        database=os.getenv('DB_NAME'),
        user=os.getenv('DB_USER'),
        password=os.getenv('DB_PASSWORD')
    )
    conn.autocommit = True  
    return conn

def get_embedding(text, bedrock_client):
    embeddings = BedrockEmbeddings(
        client=bedrock_client,
        model_id="amazon.titan-embed-text-v1"
    )
    return embeddings.embed_query(text)

def find_similar_chunks(query_embedding, k=3):
    """ê²€ìƒ‰"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT content, metadata,
                   1 - (embedding <=> %s::vector) as similarity
            FROM documents
            ORDER BY embedding <=> %s::vector
            LIMIT %s;
        """, (query_embedding, query_embedding, k))
        
        results = cursor.fetchall()
        return [(row[0], row[1]) for row in results]
    finally:
        cursor.close()
        conn.close()

def check_base_documents():
    """ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("SELECT EXISTS(SELECT 1 FROM documents LIMIT 1)")
        return cur.fetchone()[0]
    except Exception as e:
        print(f"Error checking base documents: {str(e)}")
        return False
    finally:
        cur.close()
        conn.close()

def check_recent_upload():
    """ìµœê·¼ ì—…ë¡œë“œëœ ë¬¸ì„œ í™•ì¸"""
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            SELECT EXISTS(
                SELECT 1 
                FROM documents 
                WHERE created_at >= NOW() - INTERVAL '2 minute'
            )
        """)
        return cur.fetchone()[0]
    except Exception as e:
        print(f"Error checking recent upload: {str(e)}")
        return False
    finally:
        cur.close()
        conn.close()

conversation, bedrock_client = init_bedrock()
docs_exist = check_base_documents()

st.title("ğŸ” ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")
st.caption("RAG(Retrieval-Augmented Generation) ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰")

with st.sidebar:
    with st.container():
        st.markdown("### ğŸ“‹ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. ì²˜ë¦¬ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        3. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ ë‹µë³€ì„ ë°›ìœ¼ì„¸ìš”
        """)
    
    st.markdown("---")
    
    if not st.session_state.show_upload:
        if st.button("ğŸ“„ ë¬¸ì„œ ì¶”ê°€í•˜ê¸°", key="add_doc"):
            st.session_state.show_upload = True
    
    if not docs_exist or st.session_state.show_upload:
        with st.container():
            st.markdown("### ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "PDF íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì„¸ìš”",
                type=['pdf'],
                help="PDF í˜•ì‹ë§Œ ê°€ëŠ¥"
            )
            
            if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", key="process_button", use_container_width=True):
                if uploaded_file:
                    try:
                        s3 = init_s3()
                        bucket_name = os.getenv('BUCKET_NAME')
                        file_name = uploaded_file.name
                        file_bytes = io.BytesIO(uploaded_file.getvalue())
                        
                        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            s3.upload_fileobj(
                                file_bytes,
                                bucket_name,
                                f"{file_name}",
                                ExtraArgs={'ContentType': 'application/pdf'}
                            )
                        
                        st.toast("âœ… PDFê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
                        
                        with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤...30ì´ˆ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤."):
                            time.sleep(30)

                        is_recent = check_recent_upload()
                        if is_recent:
                            st.session_state.show_upload = False
                            st.toast("âœ… ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="âœ…")
                            st.rerun()
                    except Exception as e:
                        st.error(f"âš ï¸ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                else:
                    st.warning("âš ï¸ PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.chat_history.clear()
        st.session_state.messages = []
        st.toast("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="âœ…")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

search_query = st.chat_input("ì˜ˆ: ì¡¸ì—…ìš”ê±´ì´ ë­ì•¼?")
if search_query:

    st.session_state.messages.append({"role": "user", "content": search_query})
    
    if not docs_exist:  
        st.warning("âš ï¸ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        # ì‚¬ìš©ì ì§ˆë¬¸ë§Œ í™”ë©´ì— í‘œì‹œ
        with st.chat_message("user"):
            st.write(search_query)
        
        try:
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # 1. ì§ˆë¬¸ì˜ ì„ë² ë”© ìƒì„±
                    query_embedding = get_embedding(search_query, bedrock_client)
                    
                    # 2. ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
                    similar_chunks = find_similar_chunks(query_embedding)
                    
                    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                    context = "\n\n".join([chunk[0] for chunk in similar_chunks])
                    
                    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„± 
                    prompt = HumanMessage(content=f"""ì´ì „ ëŒ€í™” ê¸°ë¡ê³¼ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
                    
                    ì§ˆë¬¸: {search_query}
                    
                    ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:
                    {context}
                    
                    ìœ„ ë‚´ìš©ê³¼ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. 
                    ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì–¸ê¸‰í•˜ì§€ ë§ê³ , í™•ì‹¤í•œ ì •ë³´ë§Œ ë‹µë³€ì— í¬í•¨í•´ì£¼ì„¸ìš”.""")
                    
                    # 5. ë‹µë³€ ìƒì„± ë° í‘œì‹œ
                    response = conversation.invoke(
                        [prompt],
                        config={"configurable": {"session_id": "default"}}
                    )
                    
                    response_content = response.content if hasattr(response, 'content') else str(response)
                    st.markdown(response_content)

                    # 6. ì°¸ê³ í•œ ë¬¸ì„œ í‘œì‹œ
                    with st.expander("ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ"):
                        for i, (content, metadata) in enumerate(similar_chunks, 1):
                            st.markdown(f"**ë¬¸ì„œ {i}:**")
                            st.write(content)
                            if metadata:
                                st.caption(f"ì¶œì²˜: {metadata.get('page', 'N/A')}í˜ì´ì§€")

                    with st.expander("ğŸ“Š ìƒì„¸ ì •ë³´"):
                        st.json({
                            "ëª¨ë¸": response.additional_kwargs.get("model_id", "N/A"),
                            "í† í° ì‚¬ìš©ëŸ‰": response.additional_kwargs.get("usage", {}),
                            "ì‘ë‹µ ID": response.id
                        })

            st.session_state.messages.append({"role": "assistant", "content": response_content})
        except Exception as e:
            st.error(f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")