# RAGAS 평가 대시보드

RAGAS(Retrieval Augmented Generation Assessment Suite)를 사용하여 RAG 시스템의 성능을 평가하고 시각화하는 Streamlit 기반 대시보드입니다.

## 주요 기능

### 1. 모델별 성능 평가 및 비교
- AWS Bedrock의 다양한 LLM 모델(Claude, Llama 등) 평가 지원
- 모델별로 결과 저장 및 비교 분석
- 직관적인 드롭다운 메뉴를 통한 모델 선택

### 2. 종합적인 평가 메트릭
- **충실도(Faithfulness)**: 모델 응답이 제공된 컨텍스트에 얼마나 충실한지 평가
- **컨텍스트 재현율(Context Recall)**: 참조 답변에 필요한 정보가 검색된 컨텍스트에 얼마나 포함되어 있는지 측정
- **컨텍스트 정밀도(Context Precision)**: 검색된 컨텍스트가 질문에 얼마나 관련이 있는지 측정
- **응답 관련성(Answer Relevancy)**: 응답이 주어진 질문에 얼마나 관련이 있는지 측정

### 3. 시각적 분석 도구
- 평균 메트릭 점수 차트
- 질문별 메트릭 히트맵
- 상세 평가 결과 테이블
- 질문별 상세 분석 패널 (시각적 메트릭 표시)

## 사용 방법

### 모델 설정 및 평가 실행
1. "평가 실행" 탭으로 이동합니다.
2. "AWS Bedrock 모델 설정" 섹션에서 사용할 모델을 선택합니다.
3. "테스트 데이터" 섹션에서 기본 제공 데이터를 사용하거나 수정합니다.
4. "평가 실행" 버튼을 클릭하여 평가를 시작합니다.

### 결과 분석
1. "평가 결과" 탭으로 이동합니다.
2. 드롭다운에서 분석할 모델 결과를 선택합니다.
3. 평균 메트릭 점수, 질문별 메트릭 히트맵, 상세 평가 결과를 확인합니다.
4. "질문별 상세 결과"에서 각 질문에 대한 자세한 분석을 확인합니다.

## 주요 기능 세부 설명

### 모델별 결과 관리
- 각 모델의 평가 결과는 `evaluation_results_{모델명}.csv` 형식으로 저장됩니다.
- 모델 간 성능 비교를 위해 결과 파일을 자동으로 관리합니다.
- 새로운 평가를 실행할 때마다 해당 모델의 결과 파일이 업데이트됩니다.

### 시각적 메트릭 표시
- 각 메트릭 점수는 색상 코드로 표시됩니다:
  - 초록색 (0.7 이상): 우수한 성능
  - 주황색 (0.4 ~ 0.7): 보통 성능
  - 빨간색 (0.4 미만): 개선 필요
- 종합 점수는 모든 메트릭의 평균으로 계산됩니다.

### 테스트 데이터 관리
- 기본 제공되는 샘플 데이터를 사용하거나 직접 수정할 수 있습니다.
- 테스트 항목 수를 조절하여 더 많거나 적은 질문으로 평가할 수 있습니다.

## 참고 사항
- Temperature는 0.1로 고정되어 있어 모델 간 일관된 비교가 가능합니다.
- 평가에는 AWS Bedrock 서비스를 사용하므로 적절한 권한이 필요합니다.
- 한글 폰트 설정이 필요한 경우 "설정" 탭에서 한글 폰트를 설정할 수 있습니다.

## 문제 해결
- **자격 증명 오류**: AWS 자격 증명이 올바르게 설정되어 있는지 확인하세요. Cloud9 환경에서는 자동으로 설정됩니다.
- **라이브러리 오류**: 필요한 모든 패키지가 설치되어 있는지 확인하세요.

